{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# This notebook helps convert BioASQ dataset into squad format.\n",
    "# By calling the appropriate functions, Snippet or abstract contexts \n",
    "# can be created. \n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "#This class helps convert the unstructured dataset to structured squad like format\n",
    "class ProcessTrainData:\n",
    "    def __init__(self,train_data_file,abs_file=None,out_dir=None):\n",
    "        self.abs_id_dict = {}\n",
    "        self.output_dir = out_dir\n",
    "        self.train_data_file = train_data_file\n",
    "        self.abstract_title_file = abs_file\n",
    "        self.train_data = \"\"\n",
    "        self.yes_no_data = {\"version\":\"BioASQ8b\",\"data\":[{\"title\":\"BioASQ8b\",\"paragraphs\":[]}]} \n",
    "        #self.yes_no_data[\"data\"][0][\"paragraphs\"]\n",
    "        \n",
    "    #Load all the abstracts document\n",
    "    def loadAbstracts(self):\n",
    "        with open(self.abstract_title_file) as csv_file:\n",
    "            csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "            line_count = 0\n",
    "            for row in csv_reader:\n",
    "                temp_str = row[1]+\" \"+row[2]\n",
    "                self.abs_id_dict[row[0]] = temp_str\n",
    "            \n",
    "    #LOAD UNFORMATTED DATASET\n",
    "    def loadDataset(self):\n",
    "        with open(self.train_data_file, 'r') as f:\n",
    "            datastore = json.load(f)\n",
    "        self.train_data = datastore\n",
    "        \n",
    "    #helper function to generate yes no question\n",
    "    def yesno_generator_abstract(self,doc_id,ques_id,question,answer):\n",
    "        if doc_id not in self.abs_id_dict:\n",
    "            print(\"Abstract not found :\",doc_id)\n",
    "            return \"nothing\"\n",
    "        abstract = self.abs_id_dict[doc_id]\n",
    "        gen_ques_context ={}\n",
    "        val = False\n",
    "        if answer==\"no\":\n",
    "            val = False\n",
    "        gen_ques_context[\"context\"] = abstract\n",
    "        if answer==\"eval\":\n",
    "            gen_ques_context[\"qas\"] =[{\"question\":question,\"id\":ques_id}] \n",
    "        else:\n",
    "            gen_ques_context[\"qas\"] =[{\"question\":question,\"id\":ques_id,\"answers\":answer,\"is_impossible\":val}] \n",
    "        return gen_ques_context\n",
    "    \n",
    "    #Gets the ID of the document from URL\n",
    "    def getDocumentId(self,url):\n",
    "        parts = url.split(\"/\")\n",
    "        return parts[len(parts)-1]\n",
    "    \n",
    "    #CREATE YES/NO DATASET with abstract\n",
    "    def CreateDataset_yesno_abstract(self):\n",
    "        no_of_ques = len(self.train_data[\"questions\"])\n",
    "        for i in range(0,no_of_ques):\n",
    "            duplicate_cnt = 0 \n",
    "            each_ques = self.train_data[\"questions\"][i]\n",
    "            if each_ques[\"type\"]!=\"yesno\":\n",
    "                continue\n",
    "            if \"exact_answer\" in each_ques:\n",
    "                answer = each_ques[\"exact_answer\"]\n",
    "            else:\n",
    "                answer = \"eval\"\n",
    "            question = each_ques[\"body\"]\n",
    "            documents = each_ques[\"documents\"]\n",
    "            ques_id = each_ques[\"id\"]\n",
    "            for j in range(len(documents)):\n",
    "                duplicate_cnt +=1\n",
    "                dup_ques_id = self.getDuplicateId(ques_id,duplicate_cnt)\n",
    "                each_doc = documents[j]\n",
    "                doc_id = self.getDocumentId(each_doc)\n",
    "                ques_context_ans_pair = self.yesno_generator_abstract(doc_id,dup_ques_id,question,answer)\n",
    "                if ques_context_ans_pair==\"nothing\":\n",
    "                    continue\n",
    "                #print(type(self.yes_no_data[\"data\"][0][\"paragraphs\"]))\n",
    "                self.yes_no_data[\"data\"][0][\"paragraphs\"].append(ques_context_ans_pair)\n",
    "                #print(self.yes_no_data)\n",
    "               \n",
    "            \n",
    "        self.WriteCSVFile(\"training_8b_abstract.json\",self.yes_no_data)\n",
    "        \n",
    "    #yes no snippet gernerator\n",
    "    def yesno_generator_snippet(self,snippet_text,ques_id, question,answer):\n",
    "        gen_ques_context ={}\n",
    "        val = False\n",
    "        if answer==\"no\":\n",
    "            val = True\n",
    "        gen_ques_context[\"context\"] = snippet_text\n",
    "        if answer==\"eval\":\n",
    "            gen_ques_context[\"qas\"] =[{\"question\":question,\"id\":ques_id}] \n",
    "        else:\n",
    "            gen_ques_context[\"qas\"] =[{\"question\":question,\"id\":ques_id,\"answers\":answer,\"is_impossible\":val}] \n",
    "        return gen_ques_context\n",
    "    #get new duplicate question id\n",
    "    def getDuplicateId(self,ques_id,cnt):\n",
    "        if len(str(cnt))==1:\n",
    "            return ques_id+\"_00\"+str(cnt)\n",
    "        if len(str(cnt))==2:\n",
    "            return ques_id+\"_0\"+str(cnt)\n",
    "        #if len(str(cnt))==3:\n",
    "        return ques_id+\"_\"+str(cnt)\n",
    "    \n",
    "    #CREATE YES/NO DATASET with snippet\n",
    "    def CreateDataset_yesno_snippet(self):\n",
    "        no_of_ques = len(self.train_data[\"questions\"])\n",
    "        for i in range(0,no_of_ques):\n",
    "            duplicate_cnt = 0\n",
    "            each_ques = self.train_data[\"questions\"][i]\n",
    "            if each_ques[\"type\"]!=\"yesno\":\n",
    "                continue\n",
    "            if \"exact_answer\" in each_ques:\n",
    "                answer = each_ques[\"exact_answer\"]\n",
    "            else:\n",
    "                answer = \"eval\"\n",
    "            question = each_ques[\"body\"]\n",
    "            snippets = each_ques[\"snippets\"]\n",
    "            ques_id = each_ques[\"id\"]\n",
    "            for j in range(len(snippets)):\n",
    "                duplicate_cnt +=1\n",
    "                dup_ques_id = self.getDuplicateId(ques_id,duplicate_cnt)\n",
    "                ques_context_ans_pair = self.yesno_generator_snippet(snippets[j][\"text\"],dup_ques_id,question,answer)\n",
    "                if ques_context_ans_pair==\"nothing\":\n",
    "                    continue\n",
    "                #print(type(self.yes_no_data[\"data\"][0][\"paragraphs\"]))\n",
    "                self.yes_no_data[\"data\"][0][\"paragraphs\"].append(ques_context_ans_pair)\n",
    "                #print(self.yes_no_data)\n",
    "        self.WriteCSVFile(\"training_8b_snippet.json\",self.yes_no_data)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def WriteCSVFile(self,filename,json_data):\n",
    "        with open(self.output_dir+filename, 'w+', encoding='utf-8') as outfile:\n",
    "            json.dump(json_data, outfile,indent=5)\n",
    "            \n",
    "    #CREATE FACTIOD DATASET\n",
    "    \n",
    "    #CREATE LIST DATASET\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract not found : 20639591\n",
      "Abstract not found : 20301779\n",
      "Abstract not found : 23304742\n",
      "Abstract not found : 20301420\n",
      "Abstract not found : 20301462\n",
      "Abstract not found : 20301585\n",
      "Abstract not found : 21249951\n",
      "Abstract not found : 22550943\n",
      "Abstract not found : 21952424\n",
      "Abstract not found : 20301466\n",
      "Abstract not found : 22129433\n",
      "Abstract not found : 22787616\n",
      "Abstract not found : 22787626\n",
      "Abstract not found : 27940438\n",
      "Abstract not found : 27940438\n"
     ]
    }
   ],
   "source": [
    "training_file = \"../Dataset/8b_dataset/training8b.json\"\n",
    "abstract_title_file = \"../Dataset/8b_dataset/titles_and_abstr_bioasq.csv\"\n",
    "out_dir ='../Dataset/8b_dataset/'\n",
    "#Initialize\n",
    "processData = ProcessTrainData(training_file,abstract_title_file,out_dir)\n",
    "#Load abstracts\n",
    "processData.loadAbstracts()\n",
    "#Load the unstructured dataset\n",
    "processData.loadDataset()\n",
    "#create strcutured dataset\n",
    "processData.CreateDataset_yesno_abstract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Absract yes/no#####################\n",
    "training_file = \"../Dataset/Task7BGoldenEnriched/7B5_golden.json\"\n",
    "abstract_title_file = \"../Dataset/8b_dataset/titles_and_abstr_bioasq.csv\"\n",
    "#Initialize\n",
    "processData = ProcessTrainData(training_file,abstract_title_file)\n",
    "#Load abstracts\n",
    "processData.loadAbstracts()\n",
    "#Load the unstructured dataset\n",
    "processData.loadDataset()\n",
    "#create strcutured dataset\n",
    "processData.CreateDataset_yesno_abstract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Snippet yes/no#####################\n",
    "\n",
    "training_file = \"../Dataset/8b_dataset/training8b.json\"\n",
    "#abstract_title_file = \"../Dataset/8b_dataset/titles_and_abstr_bioasq.csv\"\n",
    "#Initialize\n",
    "out_dir ='../Dataset/8b_dataset/'\n",
    "processData = ProcessTrainData(training_file,None,out_dir)\n",
    "\n",
    "#Load the unstructured dataset\n",
    "processData.loadDataset()\n",
    "#create strcutured dataset\n",
    "processData.CreateDataset_yesno_snippet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Absract yes/no#####################\n",
    "training_file = \"../Dataset/8b_dataset/test_sets/test1/BioASQ-task8bPhaseB-testset1.json\"\n",
    "abstract_title_file = \"../Dataset/8b_dataset/test_sets/test1/titles_and_abstr_bioasq_8b.csv\"\n",
    "out_dir ='../Dataset/8b_dataset/test_sets/test1/'\n",
    "#Initialize\n",
    "processData = ProcessTrainData(training_file,abstract_title_file,out_dir)\n",
    "#Load abstracts\n",
    "processData.loadAbstracts()\n",
    "#Load the unstructured dataset\n",
    "processData.loadDataset()\n",
    "#create strcutured dataset\n",
    "processData.CreateDataset_yesno_abstract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Snippet yes/no#####################\n",
    "\n",
    "training_file = \"../Dataset/8b_dataset/test_sets/test2/BioASQ-task8bPhaseB-testset2.json\"\n",
    "#abstract_title_file = \"../Dataset/8b_dataset/titles_and_abstr_bioasq.csv\"\n",
    "#Initialize\n",
    "out_dir ='../Dataset/8b_dataset/test_sets/test2/'\n",
    "processData = ProcessTrainData(training_file,None,out_dir)\n",
    "\n",
    "#Load the unstructured dataset\n",
    "processData.loadDataset()\n",
    "#create strcutured dataset\n",
    "processData.CreateDataset_yesno_snippet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Snippet yes/no#####################\n",
    "\n",
    "training_file = \"../Dataset/Task7BGoldenEnriched/7B5_golden.json\"\n",
    "#abstract_title_file = \"../Dataset/8b_dataset/titles_and_abstr_bioasq.csv\"\n",
    "#Initialize\n",
    "out_dir ='../Dataset/Task7BGoldenEnriched/'\n",
    "processData = ProcessTrainData(training_file,None,out_dir)\n",
    "\n",
    "#Load the unstructured dataset\n",
    "processData.loadDataset()\n",
    "#create strcutured dataset\n",
    "processData.CreateDataset_yesno_snippet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Snippet yes/no#####################\n",
    "\n",
    "training_file = \"../Dataset/8b_dataset/test_sets/test3/BioASQ-task8bPhaseB-testset3\"\n",
    "#abstract_title_file = \"../Dataset/8b_dataset/titles_and_abstr_bioasq.csv\"\n",
    "#Initialize\n",
    "out_dir ='../Dataset/8b_dataset/test_sets/test3/'\n",
    "processData = ProcessTrainData(training_file,None,out_dir)\n",
    "\n",
    "#Load the unstructured dataset\n",
    "processData.loadDataset()\n",
    "#create strcutured dataset\n",
    "processData.CreateDataset_yesno_snippet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
